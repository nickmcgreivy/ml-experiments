{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ce5bb3-fc7e-4e9d-a410-0db82a968da5",
   "metadata": {},
   "source": [
    "# What is torch.nn really?\n",
    "\n",
    "In this notebook, I'll try to reproduce (from memory, as much as possible) the pytorch tutorial [What is torch.nn really?](https://docs.pytorch.org/tutorials/beginner/nn_tutorial.html)\n",
    "\n",
    "The first step (which I will not reproduce from memory) is to download the MNIST dataset. Then I will train logistic regression without using any of the PyTorch modules `nn.Module`, `torch.optim`, `torch.Dataset`, and `torch.DataLoader`. I will then introduce these elements into my code one-by-one, showing how at each step the code gets simpler.\n",
    "\n",
    "Finally, I will replace my logistic regression model with a CNN. I will then switch from CPU to GPU, writing code that trains the CNN on a GPU device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86c8e897-aa6b-48ad-97a0-2706e654d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5e8daf-4307-4ffa-9e90-d94f060d6fac",
   "metadata": {},
   "source": [
    "### Step 1: Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3748eed-14db-4c7e-b2fb-3c2ee76c6dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "640ac6f0-463b-48c8-b25c-2e1e7a0735af",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"datasets\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"https://github.com/pytorch/tutorials/raw/main/_static/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "    content = requests.get(URL + FILENAME).content\n",
    "    (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50358779-6053-4b83-8ad0-1bf3a2f42545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "    ((x_train, y_train), (x_val, y_val), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a77779f-1da5-4c3f-b2d6-873d4f05cc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "0.99609375\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "plt.imshow(x_train[0].reshape(28, 28), cmap=\"gray\")\n",
    "print(x_train.shape)\n",
    "print(x_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c20d67-4690-4bda-912f-a3901b795c38",
   "metadata": {},
   "source": [
    "### Step 2: Convert numpy arrays to pytorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a2beb25-0dc7-46f9-af48-ee2a95cce206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "torch.float32 torch.int64\n",
      "torch.Size([50000, 784]) torch.Size([50000])\n",
      "torch.Size([10000, 784]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train), type(y_train))\n",
    "x_train, x_val, y_train, y_val = map(\n",
    "    torch.tensor, (x_train, x_val, y_train, y_val)\n",
    ")\n",
    "print(type(x_train), type(y_train))\n",
    "print(x_train.dtype, y_train.dtype)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c436dcd-3e20-492a-95b7-fe03345d06e9",
   "metadata": {},
   "source": [
    "### Step 3: Neural network from scratch\n",
    "\n",
    "Neural network training consists of loading data from batches, writing down a model, initializing parameters, writing down a loss function, computing the gradients of the loss function with respect to the parameters, and optimizing the parameters using an optimization algorithm. Let's implement each of these steps from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58af890a-7c87-4443-828f-b2a5dcbf7647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b2b3f4a2-42bf-43a9-a6a5-99e96433793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "batch_size = 64\n",
    "num_train = x_train.shape[0]\n",
    "\n",
    "\n",
    "# used for testing\n",
    "x_batch = x_train[0 : batch_size]\n",
    "y_batch = y_train[0 : batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97f4691e-1d5c-478e-bd30-42e25b580e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter initialization: Xavier normal initialization\n",
    "# weights drawn from normal distribution with mean 0, variance 2 / (n_in + n_out)\n",
    "# multiplying normal distribution with variance 1 by sigma gives variance sigma**2\n",
    "\n",
    "def init_params():\n",
    "    sigma = math.sqrt((784 + 10) / 2)\n",
    "    weight = torch.randn(784, 10) / sigma\n",
    "    bias = torch.zeros(10, requires_grad=True)\n",
    "    weight.requires_grad_()\n",
    "    return weight, bias\n",
    "\n",
    "def model(xb, weight, bias):\n",
    "    return xb @ weight + bias\n",
    "\n",
    "def loss_fn(logits, y):\n",
    "    return -(logits[range(y.shape[0]), y] - logits.exp().sum(1).log()).mean(0)\n",
    "\n",
    "def accuracy(logits, y):\n",
    "    return sum([torch.argmax(logit) == idx for logit, idx in zip(logits, y)]) / y.shape[0] \n",
    "\n",
    "def test_model(x, y, weight, bias):\n",
    "    with torch.no_grad():\n",
    "        logits = model(x, weight, bias)\n",
    "        print(loss_fn(logits, y))\n",
    "        print(accuracy(logits, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37d6a3f6-5ac8-4e2f-858d-f1725518480f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3683)\n",
      "tensor(0.1250)\n"
     ]
    }
   ],
   "source": [
    "# test that loss function works\n",
    "test_model(x_batch, y_batch, *init_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cd672ad5-1392-41a2-afce-d271c9bb45df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3455)\n",
      "tensor(0.0625)\n",
      "Epoch: 0\n",
      "tensor(1.0889)\n",
      "tensor(0.6250)\n",
      "Epoch: 1\n",
      "tensor(0.9220)\n",
      "tensor(0.7500)\n",
      "Epoch: 2\n",
      "tensor(0.8461)\n",
      "tensor(0.7500)\n",
      "Epoch: 3\n",
      "tensor(0.7980)\n",
      "tensor(0.8125)\n",
      "Epoch: 4\n",
      "tensor(0.7626)\n",
      "tensor(0.8125)\n"
     ]
    }
   ],
   "source": [
    "weight, bias = init_params()\n",
    "test_model(x_batch, y_batch, weight, bias)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    for i in range((num_train - 1) // batch_size + 1):\n",
    "        start_i = batch_size * i\n",
    "        end_i = start_i + batch_size\n",
    "        x_batch = x_train[start_i:end_i]\n",
    "        y_batch = y_train[start_i:end_i]\n",
    "        logits = model(x_batch, weight, bias)\n",
    "        loss = loss_fn(logits, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weight -= lr * weight.grad\n",
    "            bias -= lr * bias.grad\n",
    "            weight.grad.zero_()\n",
    "            bias.grad.zero_()\n",
    "    \n",
    "    test_model(x_batch, y_batch, weight, bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fd53c1-8483-4877-a781-2cbf0507c025",
   "metadata": {},
   "source": [
    "### Step 4: Use ```torch.nn.Functional``` to rewrite loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64a4121a-db7a-4c32-9b0d-d82202338944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d625798a-1781-4c18-ab56-97de2402ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.cross_entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5d244ecf-b6e3-4891-9432-f55375035767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6762)\n",
      "tensor(0.)\n",
      "Epoch: 0\n",
      "tensor(1.1138)\n",
      "tensor(0.6875)\n",
      "Epoch: 1\n",
      "tensor(0.9513)\n",
      "tensor(0.7500)\n",
      "Epoch: 2\n",
      "tensor(0.8778)\n",
      "tensor(0.7500)\n",
      "Epoch: 3\n",
      "tensor(0.8307)\n",
      "tensor(0.8125)\n",
      "Epoch: 4\n",
      "tensor(0.7954)\n",
      "tensor(0.8750)\n"
     ]
    }
   ],
   "source": [
    "weight, bias = init_params()\n",
    "test_model(x_batch, y_batch, weight, bias)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    for i in range((num_train - 1) // batch_size + 1):\n",
    "        start_i = batch_size * i\n",
    "        end_i = start_i + batch_size\n",
    "        x_batch = x_train[start_i:end_i]\n",
    "        y_batch = y_train[start_i:end_i]\n",
    "        logits = model(x_batch, weight, bias)\n",
    "        loss = loss_fn(logits, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weight -= lr * weight.grad\n",
    "            bias -= lr * bias.grad\n",
    "            weight.grad.zero_()\n",
    "            bias.grad.zero_()\n",
    "    \n",
    "    test_model(x_batch, y_batch, weight, bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83944b6-d233-468e-8fcd-44cdfd6dbbe5",
   "metadata": {},
   "source": [
    "### Step 5: Use ```nn.Module``` to keep track of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d97da9f0-9daf-43c6-b9c5-30c0b2afe8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticMnist(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(784, 10) * math.sqrt(2 / (784 + 10)))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x @ self.weight + self.bias\n",
    "\n",
    "def test_model(x, y, model):\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        print(loss_fn(logits, y))\n",
    "        print(accuracy(logits, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "185113b2-e96f-4ae0-aa18-60941ecbfdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6254)\n",
      "tensor(0.0625)\n",
      "Epoch: 0\n",
      "tensor(1.1606)\n",
      "tensor(0.6875)\n",
      "Epoch: 1\n",
      "tensor(0.9959)\n",
      "tensor(0.7500)\n",
      "Epoch: 2\n",
      "tensor(0.9219)\n",
      "tensor(0.8125)\n",
      "Epoch: 3\n",
      "tensor(0.8739)\n",
      "tensor(0.8125)\n",
      "Epoch: 4\n",
      "tensor(0.8375)\n",
      "tensor(0.8750)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticMnist()\n",
    "test_model(x_batch, y_batch, model)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    for i in range((num_train - 1) // batch_size + 1):\n",
    "        start_i = batch_size * i\n",
    "        end_i = start_i + batch_size\n",
    "        x_batch = x_train[start_i:end_i]\n",
    "        y_batch = y_train[start_i:end_i]\n",
    "        logits = model(x_batch)\n",
    "        loss = loss_fn(logits, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for p in model.parameters():\n",
    "                p -= lr * p.grad\n",
    "            model.zero_grad()\n",
    "    \n",
    "    test_model(x_batch, y_batch, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf9059a-e29e-4c78-80d3-381b3d552c39",
   "metadata": {},
   "source": [
    "### Step 6: Use ```nn.Linear``` to not have to write down parameters explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "185efdf6-415e-4145-913f-d6ab53eae542",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticMnist(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e58856d6-d7a6-463f-8bd4-82fd22dedef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3104)\n",
      "tensor(0.)\n",
      "Epoch: 0\n",
      "tensor(1.1112)\n",
      "tensor(0.7500)\n",
      "Epoch: 1\n",
      "tensor(0.9659)\n",
      "tensor(0.7500)\n",
      "Epoch: 2\n",
      "tensor(0.8978)\n",
      "tensor(0.7500)\n",
      "Epoch: 3\n",
      "tensor(0.8527)\n",
      "tensor(0.8750)\n",
      "Epoch: 4\n",
      "tensor(0.8180)\n",
      "tensor(0.8750)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticMnist()\n",
    "test_model(x_batch, y_batch, model)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    for i in range((num_train - 1) // batch_size + 1):\n",
    "        start_i = batch_size * i\n",
    "        end_i = start_i + batch_size\n",
    "        x_batch = x_train[start_i:end_i]\n",
    "        y_batch = y_train[start_i:end_i]\n",
    "        logits = model(x_batch)\n",
    "        loss = loss_fn(logits, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for p in model.parameters():\n",
    "                p -= lr * p.grad\n",
    "            model.zero_grad()\n",
    "    \n",
    "    test_model(x_batch, y_batch, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0b1fef-5717-4d84-ac2e-944723c1e3bf",
   "metadata": {},
   "source": [
    "### Step 7: Use ```torch.optim``` to simplify optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4cbe379a-c8a2-4e40-bf67-8f50ae63427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cb46aad0-98f8-401d-b0d1-a93dbefff8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3840)\n",
      "tensor(0.)\n",
      "Epoch: 0\n",
      "tensor(1.1341)\n",
      "tensor(0.7500)\n",
      "Epoch: 1\n",
      "tensor(0.9803)\n",
      "tensor(0.7500)\n",
      "Epoch: 2\n",
      "tensor(0.9077)\n",
      "tensor(0.7500)\n",
      "Epoch: 3\n",
      "tensor(0.8599)\n",
      "tensor(0.8750)\n",
      "Epoch: 4\n",
      "tensor(0.8234)\n",
      "tensor(0.8750)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticMnist()\n",
    "opt = optim.SGD(model.parameters(), lr)\n",
    "test_model(x_batch, y_batch, model)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    for i in range((num_train - 1) // batch_size + 1):\n",
    "        start_i = batch_size * i\n",
    "        end_i = start_i + batch_size\n",
    "        x_batch = x_train[start_i:end_i]\n",
    "        y_batch = y_train[start_i:end_i]\n",
    "        logits = model(x_batch)\n",
    "        loss = loss_fn(logits, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    test_model(x_batch, y_batch, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21df519-048e-4941-9a2b-6120457c343a",
   "metadata": {},
   "source": [
    "### Step 8: Use ```torch.utils.data.Dataset``` to simplify data access\n",
    "\n",
    "We will use ```torch.utils.data.TensorDataset``` which creates a dataset from tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "36d94413-ac39-40c9-96c9-09ef73a7d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "val_ds = TensorDataset(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "915e8c81-e869-4045-a426-c781f8465eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2314)\n",
      "tensor(0.1250)\n",
      "Epoch: 0\n",
      "tensor(1.0729)\n",
      "tensor(0.7500)\n",
      "Epoch: 1\n",
      "tensor(0.9233)\n",
      "tensor(0.7500)\n",
      "Epoch: 2\n",
      "tensor(0.8538)\n",
      "tensor(0.8750)\n",
      "Epoch: 3\n",
      "tensor(0.8091)\n",
      "tensor(0.8750)\n",
      "Epoch: 4\n",
      "tensor(0.7755)\n",
      "tensor(0.8750)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticMnist()\n",
    "opt = optim.SGD(model.parameters(), lr)\n",
    "test_model(x_batch, y_batch, model)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    for i in range((num_train - 1) // batch_size + 1):\n",
    "        x_batch, y_batch = train_ds[batch_size * i: batch_size * i + batch_size]\n",
    "        logits = model(x_batch)\n",
    "        loss = loss_fn(logits, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    test_model(x_batch, y_batch, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2b19f5-64e9-4ec8-8e4d-a9cca93126fc",
   "metadata": {},
   "source": [
    "### Step 9: Use ```torch.utils.data.DataLoader``` to simplify minibatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7c94faeb-a5fa-462a-b364-4d46ba6c5393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=2*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5055f663-6b7b-439a-8294-76ca90673971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3463)\n",
      "tensor(0.0625)\n",
      "0\n",
      "tensor(0.5680)\n",
      "tensor(0.8750)\n",
      "1\n",
      "tensor(0.5444)\n",
      "tensor(0.8750)\n",
      "2\n",
      "tensor(0.3321)\n",
      "tensor(0.9375)\n",
      "3\n",
      "tensor(0.2173)\n",
      "tensor(1.)\n",
      "4\n",
      "tensor(0.3622)\n",
      "tensor(0.9375)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticMnist()\n",
    "opt = optim.SGD(model.parameters(), lr)\n",
    "test_model(x_batch, y_batch, model)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(epoch)\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        logits = model(x_batch)\n",
    "        loss = loss_fn(logits, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    test_model(x_batch, y_batch, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd46043-cd8e-4396-ae65-890762653c7b",
   "metadata": {},
   "source": [
    "### Step 10: Add Model Validation \n",
    "\n",
    "Hint: don't forget ```model.eval()``` and ```with torch.no_grad():```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2a70821d-bc31-432f-947e-f19fb8d3e9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Validation loss: 0.6305475831031799\n",
      "Epoch: 1 Validation loss: 0.487580806016922\n",
      "Epoch: 2 Validation loss: 0.4319365322589874\n",
      "Epoch: 3 Validation loss: 0.40091782808303833\n",
      "Epoch: 4 Validation loss: 0.38082873821258545\n"
     ]
    }
   ],
   "source": [
    "model = LogisticMnist()\n",
    "opt = optim.SGD(model.parameters(), lr)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        logits = model(x_batch)\n",
    "        loss = loss_fn(logits, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = sum(loss_fn(model(xb), yb) for xb, yb in val_dl)\n",
    "\n",
    "    print(f\"Epoch: {epoch} Validation loss: {total_val_loss / len(val_dl)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edef6f8d-cdbc-4777-95f2-448e6fe894ec",
   "metadata": {},
   "source": [
    "### Step 11: Add ```fit()``` and ```get_data()``` functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "57f310ae-a818-4da9-bfe5-7b75f90f06c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, val_ds, batch_size):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=batch_size, shuffle=True),\n",
    "        DataLoader(val_ds, batch_size=2 * batch_size)\n",
    "    )\n",
    "\n",
    "def loss_batch(model, xb, yb, loss_fn, opt=None):\n",
    "    logits = model(xb)\n",
    "    loss = loss_fn(logits, yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    return loss.item(), len(xb)\n",
    "    \n",
    "\n",
    "def loss_eval(model, val_dl, loss_fn):\n",
    "    with torch.no_grad():\n",
    "        losses, batch_sizes = zip(*[loss_batch(model, xb, yb, loss_fn) for xb, yb in val_dl])\n",
    "        val_loss = np.sum(np.multiply(losses, batch_sizes)) / np.sum(batch_sizes)\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "def fit(model, train_dl, val_dl, loss_fn, opt, epochs):\n",
    "    model.eval()\n",
    "    val_loss = loss_eval(model, val_dl, loss_fn)\n",
    "    print(f\"Initial validation loss: {val_loss}\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, xb, yb, loss_fn, opt)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = loss_eval(model, val_dl, loss_fn)\n",
    "\n",
    "        print(f\"Epoch: {epoch} Validation loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dc4e6cb0-a180-48af-8bd9-abe4ecdc387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticMnist()\n",
    "loss_fn = F.cross_entropy\n",
    "opt = optim.SGD(model.parameters(), lr=lr)\n",
    "epochs = 5\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0998c08d-355a-4b35-8c4a-e386e5081644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = LogisticMnist()\n",
    "    opt = optim.SGD(model.parameters(), lr=lr)\n",
    "    return model, opt\n",
    "    \n",
    "model, opt = get_model()\n",
    "train_dl, val_dl = get_data(train_ds, val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "249f2bd2-2c59-422b-8b61-fc2745fa3de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial validation loss: 2.314932233428955\n",
      "Epoch: 0 Validation loss: 0.6304339765548707\n",
      "Epoch: 1 Validation loss: 0.4891471167087555\n",
      "Epoch: 2 Validation loss: 0.4341113529205322\n",
      "Epoch: 3 Validation loss: 0.4030500258684158\n",
      "Epoch: 4 Validation loss: 0.383065370631218\n"
     ]
    }
   ],
   "source": [
    "fit(model, train_dl, val_dl, loss_fn, opt, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12232204-b867-4ce2-8dee-62d25efba3a3",
   "metadata": {},
   "source": [
    "### Step 12: Switch to CNN\n",
    "\n",
    "Hint: simply apply 3 convolutional layers, followed by three ReLU layers, followed by average pooling with a window size of 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "82963cd0-fb47-4067-835a-175993c7d77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 1, 28, 28)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.avg_pool2d(x, 4)\n",
    "        return x.reshape(-1, x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "71f84b06-dea7-4084-8421-2593286f189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Mnist_CNN()\n",
    "    opt = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "    return model, opt\n",
    "\n",
    "model, opt = get_model()\n",
    "train_dl, val_dl = get_data(train_ds, val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "00edb818-2ac6-49b3-a903-abd415f6732a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial validation loss: 2.302840826034546\n",
      "Epoch: 0 Validation loss: 0.34306378083229067\n",
      "Epoch: 1 Validation loss: 0.22303513985276222\n",
      "Epoch: 2 Validation loss: 0.21057697334289552\n",
      "Epoch: 3 Validation loss: 0.18647764985561371\n",
      "Epoch: 4 Validation loss: 0.17975205611884593\n"
     ]
    }
   ],
   "source": [
    "fit(model, train_dl, val_dl, loss_fn, opt, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbbb2a8-60d9-4ff7-979c-0d7a9aa5781a",
   "metadata": {},
   "source": [
    "### Step 13: Use ```nn.Sequential```\n",
    "\n",
    "Hint: use Lambda module which initializes with function, that can be passed to ```nn.Sequential``` as module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5b93270e-fdc2-4be4-8661-f000ddca4607",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6fc46902-516d-4b92-a408-5df686f41512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    return x.reshape(-1, 1, 28, 28)\n",
    "\n",
    "def postprocess(x):\n",
    "    return x.reshape(-1, x.shape[1])\n",
    "\n",
    "def get_model():\n",
    "    model = nn.Sequential(\n",
    "        Lambda(preprocess), \n",
    "        nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.AvgPool2d(4),\n",
    "        Lambda(postprocess),\n",
    "    )                     \n",
    "    opt = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "    return model, opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "de6f5e8d-85bd-47d2-bcc8-fc1eeda31f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()\n",
    "train_dl, val_dl = get_data(train_ds, val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e4c0e64a-7b25-4983-8e93-f15dab457092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial validation loss: 2.302801552581787\n",
      "Epoch: 0 Validation loss: 0.3203518694639206\n",
      "Epoch: 1 Validation loss: 0.2484895849943161\n",
      "Epoch: 2 Validation loss: 0.20789666791558264\n",
      "Epoch: 3 Validation loss: 0.20751883352398873\n",
      "Epoch: 4 Validation loss: 0.15556487129330634\n"
     ]
    }
   ],
   "source": [
    "fit(model, train_dl, val_dl, loss_fn, opt, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81293de7-6d64-4278-8c3c-606ce1b1274b",
   "metadata": {},
   "source": [
    "### Step 14: Use wrapped ```DataLoader```\n",
    "\n",
    "Hint: create a class with the methods ```__iter__``` and ```__len__``` which yields the next batch and applies a function to the dataset. This function will be our preprocessing function for the CNN which converts the length-784 array into 28x28. \n",
    "\n",
    "Hint: replace ```nn.AvgPool2d``` with ```nn.AdaptiveAvgPool2d``` which takes one argument, ```output_size```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f7fa871b-175b-4c98-8258-2bc99a933159",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield self.func(*b)\n",
    "\n",
    "def get_model():\n",
    "    model = nn.Sequential( \n",
    "        nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        Lambda(postprocess),\n",
    "    )                     \n",
    "    opt = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "    return model, opt\n",
    "\n",
    "def preprocess(x, y):\n",
    "    return x.reshape(-1, 1, 28, 28), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "302f416f-3b3e-4fb4-9684-3afa88a520ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, val_dl = get_data(train_ds, val_ds, batch_size)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "val_dl = WrappedDataLoader(val_dl, preprocess)\n",
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6606da98-69e7-48d7-a32a-11b0dc172488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial validation loss: 2.303780846786499\n",
      "Epoch: 0 Validation loss: 0.3385274554491043\n",
      "Epoch: 1 Validation loss: 0.3311109385251999\n",
      "Epoch: 2 Validation loss: 0.2782747683763504\n",
      "Epoch: 3 Validation loss: 0.22899432329833508\n",
      "Epoch: 4 Validation loss: 0.18766014320254326\n"
     ]
    }
   ],
   "source": [
    "fit(model, train_dl, val_dl, loss_fn, opt, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59fb289-34a0-4fce-85e3-f311fba09064",
   "metadata": {},
   "source": [
    "### Step 15: Run on GPU\n",
    "\n",
    "hint: use ```.to(device)``` for both tensors and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1c919a41-af2e-4a79-98c1-cb6832f85f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "# this code won't work in old version of torch, but might work in Colab\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4ec4afe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5)\n",
    "x = x.to(device)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8e8838c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x.reshape(-1, 1, 28, 28).to(device), y.to(device)\n",
    "\n",
    "def get_model():\n",
    "    model = nn.Sequential( \n",
    "        nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        Lambda(postprocess),\n",
    "    )                     \n",
    "    opt = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "    return model.to(device), opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0c373ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, val_dl = get_data(train_ds, val_ds, batch_size)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "val_dl = WrappedDataLoader(val_dl, preprocess)\n",
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e1fe6f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.mps.FloatTensor\n",
      "torch.Size([64]) torch.mps.LongTensor\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_dl:\n",
    "    print(X.shape, X.type())\n",
    "    print(y.shape, y.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "73523426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial validation loss: 2.302761427307129\n",
      "Epoch: 0 Validation loss: 0.3885533068656921\n",
      "Epoch: 1 Validation loss: 0.2600893201589584\n",
      "Epoch: 2 Validation loss: 0.22128414344787598\n",
      "Epoch: 3 Validation loss: 0.21105054746866225\n",
      "Epoch: 4 Validation loss: 0.1956888154923916\n"
     ]
    }
   ],
   "source": [
    "fit(model, train_dl, val_dl, loss_fn, opt, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4aea43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
